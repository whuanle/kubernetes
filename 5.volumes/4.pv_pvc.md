# 5.4 PV、PVC

### 导读

PersistentVolume、Persistentvolumeclaims



### 如何使用 PV、PVC

#### 创建 NFS 

首先根据上一章中的 NFS 教程，安装好对应的 NFS Server 和 Client。

我们在一台服务器的 `/data/volumns` 目录中，创建五个目录，五个目录用作 NFS 存储空间，为其它 Kubernetes 中的 Pod 提供卷服务。

```shell
mkdir /data
mkdir /data/volumns
mkdir /data/volumns/1
mkdir /data/volumns/2
mkdir /data/volumns/3
mkdir /data/volumns/4
mkdir /data/volumns/5
```



```
echo "/data/volumns/1 *(rw,no_root_squash,sync)" >> /etc/exports
echo "/data/volumns/2 *(rw,no_root_squash,sync)" >> /etc/exports
echo "/data/volumns/3 *(rw,no_root_squash,sync)" >> /etc/exports
echo "/data/volumns/4 *(rw,no_root_squash,sync)" >> /etc/exports
echo "/data/volumns/5 *(rw,no_root_squash,sync)" >> /etc/exports
```

使配置生效

```
exportfs -r
```



```
exportfs
```

```
root@instance-r0zrc5gb:~# exportfs
/data/volumns/1
		<world>
/data/volumns/2
		<world>
/data/volumns/3
		<world>
/data/volumns/4
		<world>
/data/volumns/5
		<world>
```



#### 创建 PV



```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
   name: pv001
   labels:
     name: pv001
spec:
   nfs:
     path: /data/volumes/1
     server: 192.168.9.99
   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]
   capacity:
     storage: 1Gi
---
apiVersion: v1
kind: PersistentVolume
metadata:
   name: pv002
   labels:
     name: pv002
spec:
   nfs:
     path: /data/volumes/2
     server: 192.168.9.99
   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]
   capacity:
     storage: 2Gi
---
apiVersion: v1
kind: PersistentVolume
metadata:
   name: pv003
   labels:
     name: pv003
spec:
   nfs:
     path: /data/volumes/3
     server: 192.168.9.99
   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]
   capacity:
     storage: 4Gi
---
apiVersion: v1
kind: PersistentVolume
metadata:
   name: pv004
   labels:
     name: pv004
spec:
   nfs:
     path: /data/volumes/4
     server: 192.168.9.99
   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]
   capacity:
     storage: 8Gi
---
apiVersion: v1
kind: PersistentVolume
metadata:
   name: pv005
   labels:
     name: pv005
spec:
   nfs:
     path: /data/volumes/5
     server: 192.168.9.99
   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]
   capacity:
     storage: 10Gi
```

>  请替换 `192.168.9.99` 为你的 NFS Server IP。
>
>  `   accessModes: [ "ReadWriteMany" , "ReadWriteOnce" ]` 表示可以被多节点同时读，某一刻只能被一个节点写。



```
root@VM-8-5-ubuntu:~# kubectl apply -f pv-demo.yaml 
persistentvolume/pv001 created
persistentvolume/pv002 created
persistentvolume/pv003 created
persistentvolume/pv004 created
persistentvolume/pv005 created
```

![pv1](H:\文章\K8S基础教程与CKAD认证\5.volumes\.images\pv1.png)

> 所有 PV 都处于 Available 状态。



#### 创建 PVC

```yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: pvc1
spec:
  accessModes: ["ReadWriteMany"]
  resources:
    requests:
      storage: 3Gi
```

```text
kubectl apply -f pvc1.yaml
```



```
root@VM-8-5-ubuntu:~# kubectl get pv
NAME    CAPACITY   ACCESS MODES   RECLAIM POLICY   STATUS     CLAIM  
pv001   1Gi        RWO,RWX        Retain           Available                            
pv002   2Gi        RWO,RWX        Retain           Available                             
pv003   4Gi        RWO,RWX        Retain           Bound      default/pvc1               
pv004   8Gi        RWO,RWX        Retain           Available 
pv005   10Gi       RWO,RWX        Retain           Available   
```

刚开始时，状态是 Pending，如果找到合适的 PV 对象，绑定后，会变成 Bound 状态。



#### 在 Pod 中使用

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - image: nginx:latest
        name: nginx
        volumeMounts:
        - name: nfs-data
          mountPath: /data/wwwroot
      volumes: 
      - name: nfs-data
        persistentVolumeClaim:
          claimName: pvc1
```



### 访问模式 

PersistentVolume 卷可以用资源提供者所支持的任何方式挂载到宿主系统上。 如下表所示，提供者（驱动）的能力不同，每个 PV 卷的访问模式都会设置为 对应卷所支持的模式值。 例如，NFS 可以支持多个读写客户，但是某个特定的 NFS PV 卷可能在服务器 上以只读的方式导出。每个 PV 卷都会获得自身的访问模式集合，描述的是 特定 PV 卷的能力。

访问模式有：

- ReadWriteOnce -- 卷可以被一个节点以读写方式挂载；
- ReadOnlyMany -- 卷可以被多个节点以只读方式挂载；
- ReadWriteMany -- 卷可以被多个节点以读写方式挂载。

在命令行接口（CLI）中，访问模式也使用以下缩写形式：

- RWO - ReadWriteOnce
- ROX - ReadOnlyMany
- RWX - ReadWriteMany

> **重要提醒！** 每个卷只能同一时刻只能以一种访问模式挂载，即使该卷能够支持 多种访问模式。例如，一个 GCEPersistentDisk 卷可以被某节点以 ReadWriteOnce 模式挂载，或者被多个节点以 ReadOnlyMany 模式挂载，但不可以同时以两种模式 挂载。

| 卷插件               | ReadWriteOnce | ReadOnlyMany | ReadWriteMany |
| :------------------- | :-----------: | :----------: | :-----------: |
| AWSElasticBlockStore |       ✓       |      -       |       -       |
| AzureFile            |       ✓       |      ✓       |       ✓       |
| AzureDisk            |       ✓       |      -       |       -       |
| CephFS               |       ✓       |      ✓       |       ✓       |
| Cinder               |       ✓       |      -       |       -       |
| CSI                  |  取决于驱动   |  取决于驱动  |  取决于驱动   |
| FC                   |       ✓       |      ✓       |       -       |
| FlexVolume           |       ✓       |      ✓       |  取决于驱动   |
| Flocker              |       ✓       |      -       |       -       |
| GCEPersistentDisk    |       ✓       |      ✓       |       -       |
| Glusterfs            |       ✓       |      ✓       |       ✓       |
| HostPath             |       ✓       |      -       |       -       |



### PV、PVC 状态



### 阶段 

每个卷会处于以下阶段（Phase）之一：

- Available（可用）-- 卷是一个空闲资源，尚未绑定到任何申领；
- Bound（已绑定）-- 该卷已经绑定到某申领；
- Released（已释放）-- 所绑定的申领已被删除，但是资源尚未被集群回收；
- Failed（失败）-- 卷的自动回收操作失败。

命令行接口能够显示绑定到某 PV 卷的 PVC 对象。